{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0412 13:15:51.264096 140736272999360 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "# from tensorflow.contrib import layers\n",
    "from tensorflow.python.ops import nn_impl\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "# from recall.data_process import get_batch\n",
    "from utils.utils import list2array\n",
    "from utils.config import SuperPrams\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # 获取分批数据 \n",
    "def get_batch(page_no=0, page_size=10000):\n",
    "    with open('./data/recall/feature.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) <= page_no:\n",
    "            return False, [], [], [], [], []\n",
    "        video_ids_batch = []\n",
    "        search_id_batch = []\n",
    "        age_batch = []\n",
    "        gender_batch = []\n",
    "        label_batch = []\n",
    "        for i in range(page_no * page_size, len(lines)):\n",
    "            content = lines[i]\n",
    "            info_list = content.split(',')\n",
    "            video_ids_batch.append(info_list[1].split('#'))\n",
    "            search_id_batch.append(info_list[2].split('#'))\n",
    "            age_batch.append(info_list[3])\n",
    "            gender_batch.append(info_list[4])\n",
    "            label_batch.append(info_list[5].strip())\n",
    "        return True, video_ids_batch, search_id_batch, age_batch, gender_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Args(SuperPrams):\n",
    "    def __init__(self, is_training=True):\n",
    "        self.is_training = is_training\n",
    "        self.dnn_depth = 3\n",
    "        self.learning_rate = 0.01\n",
    "        self.epoch = 10\n",
    "        self.checkpoint_dir = '/Users/jun_yu/Documents/CTR_MODLE/youtube_dnn/data/recall/checkpoint_dir'\n",
    "\n",
    "\n",
    "class RecallModel:\n",
    "    def __init__(self, args):\n",
    "        self.video_total_num = args.video_total_num\n",
    "        self.search_total_num = args.search_total_num\n",
    "        self.depth = args.dnn_depth\n",
    "        self.units_list = [128] * self.depth\n",
    "        self.learning_rate = args.learning_rate\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.class_distinct = args.class_total_num\n",
    "        self.batch_num = args.batch_num\n",
    "        self.is_training = args.is_training\n",
    "        self.init_graph()\n",
    "\n",
    "    def init_graph(self):\n",
    "        # 初始化喂入参数，placeholder名字要唯一，不能更改placeholder的任何信息\n",
    "        self.video_ids_ph = tf.placeholder(tf.int32, shape=[None, None], name='video_ids')\n",
    "        self.search_id_ph = tf.placeholder(tf.int32, shape=[None], name='search_id')\n",
    "        self.age_ph = tf.placeholder(tf.float32, shape=[None], name='age')\n",
    "        self.gender_ph = tf.placeholder(tf.float32, shape=[None], name='gender')\n",
    "        self.label_ph = tf.placeholder(tf.float32, shape=[None], name='label_ph')\n",
    "\n",
    "        # 初始化视频embedding、搜索条件的embedding，concat两个embedding和age、gender\n",
    "        video_embedding = tf.get_variable('video_embedding', shape=[self.video_total_num], dtype=tf.float32,\n",
    "                                          initializer=tf.variance_scaling_initializer())\n",
    "        video_vecs = tf.nn.embedding_lookup(video_embedding, self.video_ids_ph)\n",
    "        search_embedding = tf.get_variable(name='search_embedding', shape=[self.search_total_num], dtype=tf.float32,\n",
    "                                           initializer=tf.variance_scaling_initializer())\n",
    "        search_vec = tf.nn.embedding_lookup(search_embedding, self.search_id_ph)\n",
    "        input = tf.concat([tf.reshape(tf.reduce_mean(video_vecs, axis=1), shape=[-1, 1]),\n",
    "                           tf.reshape(search_vec, shape=[-1, 1]), tf.reshape(self.age_ph, shape=[-1, 1]),\n",
    "                           tf.reshape(self.gender_ph, shape=[-1, 1])], axis=1)\n",
    "\n",
    "        # 经过多层深度训练，层数根据mAP确定\n",
    "        for i in range(self.depth):\n",
    "            input = tf.layers.dense(inputs=input, units=self.units_list[i],\n",
    "                                    kernel_regularizer= tf.keras.regularizers.l2(0.001), \n",
    "                                    activation=tf.nn.relu,\n",
    "                                    name='fc{}'.format(i), trainable=self.is_training)\n",
    "            input = tf.layers.batch_normalization(input, training=self.is_training, name='fc{}_bn'.format(i))\n",
    "        output = input\n",
    "        # 初始化类别（就是每个视频的标签，对应论文中的百万级）的embedding对应的：weights和bias\n",
    "        weights = tf.get_variable('soft_weight', shape=[self.class_distinct, 128],\n",
    "                                  initializer=tf.variance_scaling_initializer())\n",
    "        biases = tf.get_variable('soft_bias', shape=[self.class_distinct],\n",
    "                                 initializer=tf.variance_scaling_initializer())\n",
    "        if not self.is_training:\n",
    "            # 计算预测值\n",
    "            self.logits_out = tf.matmul(output, tf.transpose(weights))\n",
    "        else:\n",
    "            # label必须二维的，但是biases却是一维的\n",
    "            self.labels = tf.reshape(self.label_ph, shape=[-1, 1])\n",
    "            # 计算损失, num_true=1代表负采样有一个正例，one-hot值为1。\n",
    "            self.logits_out, self.labels_out = nn_impl._compute_sampled_logits(weights=weights, biases=biases,\n",
    "                                                                               labels=self.labels,\n",
    "                                                                               inputs=input, num_sampled=100,\n",
    "                                                                               num_classes=self.class_distinct,\n",
    "                                                                               num_true=1,\n",
    "                                                                               sampled_values=None,\n",
    "                                                                               remove_accidental_hits=True,\n",
    "                                                                               partition_strategy=\"div\",\n",
    "                                                                               name=\"sampled_softmax_loss\",\n",
    "                                                                               seed=None)\n",
    "            labels = array_ops.stop_gradient(self.labels_out, name=\"labels_stop_gradient\")\n",
    "            sampled_losses = nn_ops.softmax_cross_entropy_with_logits_v2(labels=labels, logits=self.logits_out)\n",
    "            self.loss = tf.reduce_mean(sampled_losses)\n",
    "            # 获得梯度下降优化器\n",
    "            gradient_descent_optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "            train_var = tf.trainable_variables()\n",
    "            clip_gradients, _ = tf.clip_by_global_norm(tf.gradients(self.loss, train_var), 5)\n",
    "            self.gradient_descent = gradient_descent_optimizer.apply_gradients(zip(clip_gradients, train_var),\n",
    "                                                                               global_step=self.global_step)\n",
    "\n",
    "    def train(self, session, video_ids, search_id, age, gender, label):\n",
    "        loss, _, step, logits, labels = session.run(\n",
    "            [self.loss, self.gradient_descent, self.global_step, self.labels_out, self.logits_out],\n",
    "            feed_dict={self.video_ids_ph: video_ids,\n",
    "                       self.search_id_ph: search_id,\n",
    "                       self.age_ph: age,\n",
    "                       self.gender_ph: gender,\n",
    "                       self.label_ph: label\n",
    "                       })\n",
    "        return loss, step, logits, labels\n",
    "\n",
    "    def predict(self, session, video_ids, search_id, age, gender):\n",
    "        result = session.run([self.logits_out],\n",
    "                             feed_dict={self.video_ids_ph: video_ids,\n",
    "                                        self.search_id_ph: search_id,\n",
    "                                        self.age_ph: age,\n",
    "                                        self.gender_ph: gender})\n",
    "        return result\n",
    "\n",
    "    def cal_acc(self, session, label, logit):\n",
    "        labels = tf.one_hot(label, self.class_distinct, axis=1)\n",
    "        correct_pred = tf.equal(tf.argmax(logit, 1), tf.argmax(labels, 1))\n",
    "        accuracy, labels, logits = session.run([tf.reduce_mean(tf.cast(correct_pred, tf.float32)), labels, logit])\n",
    "        return accuracy, labels, logits\n",
    "\n",
    "    def save(self, session, path):\n",
    "        tf.train.Saver().save(session, path)\n",
    "\n",
    "    def restore(self, session, path):\n",
    "        tf.train.Saver().restore(session, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 运行图\n",
    "def run_graph(training=True):\n",
    "    args = Args(is_training=training)\n",
    "    # 可以增加gpu使用的设置\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as session:\n",
    "        recall_model = RecallModel(args)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.local_variables_initializer())\n",
    "        if args.is_training:\n",
    "            for i in range(args.epoch):\n",
    "                j = 0\n",
    "                while True:\n",
    "                    has_more, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = get_batch(\n",
    "                        page_size=args.batch_num)\n",
    "                    if not has_more:\n",
    "                        break\n",
    "#                     print(video_ids_batch)\n",
    "#                     video_ids_batch, search_ids_batch = list2array(video_ids_batch, dtype='int32'), list2array(search_ids_batch, 'int32'), \n",
    "                    age_batch, gender_batch, label_batch = list2array(age_batch), list2array(gender_batch), list2array(label_batch)\n",
    "                    \n",
    "#                     loss, step, logits, labels = recall_model.train(session, video_ids_batch, search_ids_batch,\n",
    "#                                                                     age_batch,\n",
    "#                                                                     gender_batch, label_batch)\n",
    "#                     print(loss, step)\n",
    "#                     if j % 1 == 0:\n",
    "#                         recall_model.save(session, args.checkpoint_dir + 'utube')\n",
    "#                     j += 1\n",
    "#         else:\n",
    "#             recall_model.restore(session, args.checkpoint_dir)\n",
    "#             has_more, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = get_batch(2,\n",
    "#                 page_size=args.batch_num)\n",
    "#             if has_more:\n",
    "#                 video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = list2array(video_ids_batch, 'int32'), list2array(\n",
    "#                     search_ids_batch, 'int32'), list2array(age_batch), list2array(gender_batch), list2array(label_batch)\n",
    "#                 logits = recall_model.predict(session, video_ids_batch, search_ids_batch, age_batch, gender_batch)[0]\n",
    "#                 logits = tf.convert_to_tensor(logits, tf.float32, name='predict_logits')\n",
    "#                 accuracy, labels, logits = recall_model.cal_acc(session, label=label_batch, logit=logits)\n",
    "#                 print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     run_graph(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
