{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 全量视频id 对应的视频标签 \n",
    "import json \n",
    "with open('./data/recall/videoid_videoclass.txt','r') as fin:\n",
    "    data = fin.readlines()\n",
    "    \n",
    "data_list = data[0].split(',')\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1169"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = list(set(data_list))\n",
    "len(new_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1130', '359', '225', '1088', '624', '16', '951', '716', '461', '935']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 全量行为记录(uid, 观看ids, 搜索ids, 年龄, 性别, label) \n",
    "with open('./data/recall/feature.txt','r') as file_feature:\n",
    "    feature = file_feature.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['380',\n",
       " '625#646#5910#4593#511#357#9040#5648#509#3813#2494#144#445#684#4382#466#514#5015#547#387#1107#570#291#2237#594#501',\n",
       " '593#409#0',\n",
       " '38',\n",
       " '1',\n",
       " '339']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[0].rstrip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for line in feature:\n",
    "    feature_dict = {}\n",
    "    feature_data = line.rstrip().split(',')\n",
    "    feature_dict['uid'] = feature_data[0]\n",
    "    feature_dict['view_id'] = feature_data[1].split('#')\n",
    "    feature_dict['search_id'] = feature_data[2].split('#')\n",
    "    feature_dict['age']  = feature_data[3]\n",
    "    feature_dict['sex']  = feature_data[4]\n",
    "    feature_dict['lable'] = feature_data[5]\n",
    "    feature_list.append(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': '38',\n",
       "  'lable': '339',\n",
       "  'search_id': ['593', '409', '0'],\n",
       "  'sex': '1',\n",
       "  'uid': '380',\n",
       "  'view_id': ['625',\n",
       "   '646',\n",
       "   '5910',\n",
       "   '4593',\n",
       "   '511',\n",
       "   '357',\n",
       "   '9040',\n",
       "   '5648',\n",
       "   '509',\n",
       "   '3813',\n",
       "   '2494',\n",
       "   '144',\n",
       "   '445',\n",
       "   '684',\n",
       "   '4382',\n",
       "   '466',\n",
       "   '514',\n",
       "   '5015',\n",
       "   '547',\n",
       "   '387',\n",
       "   '1107',\n",
       "   '570',\n",
       "   '291',\n",
       "   '2237',\n",
       "   '594',\n",
       "   '501']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import warnings \n",
    "import h5py\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.resetwarnings()\n",
    "import numpy as np \n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# py upgrade from v1 to v2 \n",
    "# !tf_upgrade_v2 --infile ./recall/model.py  --outfile ./recall_model.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "# from tensorflow.compat.v1.contrib import layers \n",
    "# from tensorflow.compat.v1.python.ops import nn_impl\n",
    "# from tensorflow.compat.v1.python.ops import array_ops\n",
    "# from tensorflow.compat.v1.python.ops import nn_ops\n",
    "\n",
    "# from utils.utils import list2array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n",
      "(11, 22, 33)\n"
     ]
    }
   ],
   "source": [
    "a = [[1,11],[2,22],[3,33]]\n",
    "for i in zip(*a):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # 获取分批数据 \n",
    "def get_batch(page_no=0, page_size=10000):\n",
    "    with open('./data/recall/feature.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) <= page_no:\n",
    "            return False, [], [], [], [], []\n",
    "        video_ids_batch = []\n",
    "        search_id_batch = []\n",
    "        age_batch = []\n",
    "        gender_batch = []\n",
    "        label_batch = []\n",
    "        for i in range(page_no * page_size, len(lines)):\n",
    "            content = lines[i]\n",
    "            info_list = content.split(',')\n",
    "            video_ids_batch.append(info_list[1].split('#'))\n",
    "            search_id_batch.append(info_list[2].split('#'))\n",
    "            age_batch.append(info_list[3])\n",
    "            gender_batch.append(info_list[4])\n",
    "            label_batch.append(info_list[5].strip())\n",
    "        return True, video_ids_batch, search_id_batch, age_batch, gender_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取行为总条数, 采样共7001条\n",
    "def get_total_num():\n",
    "    with open('./data/recall/feature.txt', 'r') as f:\n",
    "        return len(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2array(input, dtype='f'):\n",
    "#     input = np.concatenate(input, axis=0)\n",
    "    if dtype == 'f': \n",
    "        return np.array(input, dtype=np.float32)\n",
    "    return np.array(input, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bool, 视频id列表, 搜索id列表, 年龄, 性别, 标签 \n",
    "has_more, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# video_ids_batch = list2array(video_ids_batch, dtype='int32') \n",
    "# search_ids_batch = list2array(search_ids_batch, 'int32') \n",
    "age_batch = list2array(age_batch) \n",
    "gender_batch = list2array(gender_batch) \n",
    "label_batch = list2array(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import SuperPrams \n",
    "args = SuperPrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_total_num = args.video_total_num\n",
    "search_total_num = args.search_total_num\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "class_distinct = args.class_total_num\n",
    "batch_num = args.batch_num\n",
    "\n",
    "is_training = True \n",
    "dnn_depth = 3\n",
    "learning_rate = 0.01\n",
    "epoch = 10 \n",
    "depth = dnn_depth\n",
    "units_list = [128] * depth \n",
    "checkpoint_dir = './data/recall/checkpoint_dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable video_embedding already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1991e08b7de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                                             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_total_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                             initializer=tf.compat.v1.variance_scaling_initializer())\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mvideo_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_ids_ph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1502\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1245\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;31m# ResourceVariables don't have an op associated with so no traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;31m# Throw away internal tf entries and only take a few lines. In some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable video_embedding already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "# tf.compat.v1.disable_eager_execution() \n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "# 初始化喂入参数，placeholder名字要唯一，不能更改placeholder的任何信息\n",
    "video_ids_ph = tf.compat.v1.placeholder(tf.int32, shape=[None, None], name='video_ids')\n",
    "search_id_ph = tf.compat.v1.placeholder(tf.int32, shape=[None], name='search_id')\n",
    "age_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='age')\n",
    "gender_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='gender')\n",
    "label_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='label_ph')\n",
    "\n",
    "# 初始化视频embedding、搜索条件的embedding，concat两个embedding和age、gender\n",
    "video_embedding = tf.compat.v1.get_variable('video_embedding', \n",
    "                                            shape=[video_total_num], \n",
    "                                            dtype=tf.float32,\n",
    "                                            initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "\n",
    "video_vecs = tf.nn.embedding_lookup(params=video_embedding, ids=video_ids_ph)\n",
    "\n",
    "search_embedding = tf.compat.v1.get_variable(name='search_embedding', \n",
    "                                             shape=[search_total_num], \n",
    "                                             dtype=tf.float32,\n",
    "                                             initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "\n",
    "search_vec = tf.nn.embedding_lookup(params=search_embedding, ids=search_id_ph)\n",
    "\n",
    "input = tf.concat([tf.reshape(tf.reduce_mean(input_tensor=video_vecs, axis=1), shape=[-1, 1]),\n",
    "                   tf.reshape(search_vec, shape=[-1, 1]), \n",
    "                   tf.reshape(age_ph, shape=[-1, 1]),\n",
    "                   tf.reshape(gender_ph, shape=[-1, 1])], axis=1)\n",
    "\n",
    "# 经过多层深度训练，层数根据mAP确定\n",
    "for i in range(depth):\n",
    "    input = tf.compat.v1.layers.dense(inputs=input,\n",
    "                                      units= units_list[i],\n",
    "                                      kernel_regularizer= tf.keras.regularizers.l2(0.001),\n",
    "                                      activation= tf.nn.relu,\n",
    "                                      name='fc{}'.format(i), \n",
    "                                      trainable=is_training) \n",
    "\n",
    "    input = tf.keras.layers.batch_normalization(inputs=input,\n",
    "                                                training = is_training, \n",
    "                                                name='fc{}_bn'.format(i))\n",
    "\n",
    "output = input\n",
    "\n",
    "# 初始化类别（就是每个视频的标签，对应论文中的百万级）的embedding对应的：weights和bias\n",
    "weights = tf.compat.v1.get_variable('soft_weight', \n",
    "                                    shape=[class_distinct, 128],\n",
    "                                    initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "\n",
    "biases = tf.compat.v1.get_variable('soft_bias',\n",
    "                                   shape=[class_distinct],\n",
    "                                   initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "if not is_training:\n",
    "    # 计算预测值\n",
    "    logits_out = tf.matmul(output, tf.transpose(a=weights))\n",
    "else:\n",
    "    # label必须二维的，但是biases却是一维的\n",
    "    labels = tf.reshape(label_ph, shape=[-1, 1])\n",
    "    # 计算损失, num_true=1代表负采样有一个正例，one-hot值为1。\n",
    "    logits_out, labels_out = tf.compat.v1.nn.sampled_softmax_loss(weights=weights,\n",
    "                                                                            biases=biases, \n",
    "                                                                            labels=labels,\n",
    "                                                                            inputs=input, \n",
    "                                                                            num_sampled=100,\n",
    "                                                                            num_classes=class_distinct,\n",
    "                                                                            num_true=1,\n",
    "                                                                            sampled_values=None,\n",
    "                                                                            remove_accidental_hits=True,\n",
    "                                                                            partition_strategy=\"div\",\n",
    "                                                                            name=\"sampled_softmax_loss\",\n",
    "                                                                            seed=None)\n",
    "    # labels = array_ops.stop_gradient(self.labels_out, name=\"labels_stop_gradient\")\n",
    "    labels = tf.stop_gradient(labels_out, \n",
    "                              name=\"labels_stop_gradient\")\n",
    "    # sampled_losses = nn_ops.softmax_cross_entropy_with_logits_v2(labels=labels, logits=self.logits_out)\n",
    "    sampled_losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, \n",
    "                                                                logits=logits_out)\n",
    "\n",
    "    loss = tf.reduce_mean(input_tensor=sampled_losses)\n",
    "    # 获得梯度下降优化器\n",
    "    gradient_descent_optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_var = tf.compat.v1.trainable_variables()\n",
    "    clip_gradients, _ = tf.clip_by_global_norm(tf.gradients(ys=loss, xs=train_var), 5)\n",
    "\n",
    "    gradient_descent = gradient_descent_optimizer.apply_gradients(zip(clip_gradients, train_var), \n",
    "                                                                       global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(session, video_ids, search_id, age, gender, label):\n",
    "    loss, _, step, logits, labels = session.run([loss, \n",
    "                                                 gradient_descent, \n",
    "                                                 global_step, \n",
    "                                                 labels_out, \n",
    "                                                 logits_out],\n",
    "        feed_dict={video_ids_ph: video_ids,\n",
    "                   search_id_ph: search_id,\n",
    "                   age_ph: age,\n",
    "                   gender_ph: gender,\n",
    "                   label_ph: label})\n",
    "\n",
    "    return loss, step, logits, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(session, video_ids, search_id, age, gender):\n",
    "    result = session.run([logits_out],\n",
    "                         feed_dict={video_ids_ph: video_ids,\n",
    "                                    search_id_ph: search_id,\n",
    "                                    age_ph: age,\n",
    "                                    gender_ph: gender})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_acc(session, label, logit):\n",
    "    labels = tf.one_hot(label, class_distinct, axis=1)\n",
    "    correct_pred = tf.equal(tf.argmax(input=logit, axis=1), \n",
    "                            tf.argmax(input=labels, axis=1))\n",
    "\n",
    "    accuracy, labels, logits = session.run([tf.reduce_mean(input_tensor=tf.cast(correct_pred, tf.float32)), \n",
    "                                            labels, logit])\n",
    "    return accuracy, labels, logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(session, path):\n",
    "    tf.compat.v1.train.Saver().save(session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore(session, path):\n",
    "    tf.compat.v1.train.Saver().restore(session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = 'True' \n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "    \n",
    "for i in range(args.epoch):\n",
    "    j = 0\n",
    "    while True:\n",
    "        has_more, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = get_batch(page_size=args.batch_num)\n",
    "\n",
    "        step = train(session, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch)\n",
    "\n",
    "        print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/_lib/_numpy_compat.py:10: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated since 1.15.0, import from numpy.testing instead.\n",
      "  from numpy.testing.nosetester import import_nose\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:12: DeprecationWarning: Importing from numpy.testing.decorators is deprecated since numpy 1.15.0, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import setastest\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 61] Connection refused>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 936\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e3015d1a6000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 413\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1361\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 61] Connection refused>"
     ]
    }
   ],
   "source": [
    "# mlp for binary classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "df = read_csv(path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "# make a prediction\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.config import SuperPrams \n",
    "tf.compat.v1.enable_eager_execution()\n",
    "class Args(SuperPrams):\n",
    "    def __init__(self, is_training=True):\n",
    "#         self.is_training = is_training\n",
    "        self.is_training = True \n",
    "        self.dnn_depth = 3\n",
    "        self.learning_rate = 0.01\n",
    "        self.epoch = 10\n",
    "        self.checkpoint_dir = './data/recall/checkpoint_dir/'\n",
    "\n",
    "\n",
    "class RecallModel:\n",
    "    def __init__(self, args):\n",
    "        self.video_total_num = args.video_total_num\n",
    "        self.search_total_num = args.search_total_num\n",
    "        self.depth = args.dnn_depth\n",
    "        self.units_list = [128] * self.depth\n",
    "        self.learning_rate = args.learning_rate\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.class_distinct = args.class_total_num\n",
    "        self.batch_num = args.batch_num\n",
    "        self.is_training = args.is_training\n",
    "        self.init_graph()\n",
    "    \n",
    "    def init_graph(self):\n",
    "        # 初始化喂入参数，placeholder名字要唯一，不能更改placeholder的任何信息\n",
    "        self.video_ids_ph = tf.compat.v1.placeholder(tf.int32, shape=[None, None], name='video_ids')\n",
    "        self.search_id_ph = tf.compat.v1.placeholder(tf.int32, shape=[None], name='search_id')\n",
    "        self.age_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='age')\n",
    "        self.gender_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='gender')\n",
    "        self.label_ph = tf.compat.v1.placeholder(tf.float32, shape=[None], name='label_ph')\n",
    "\n",
    "        # 初始化视频embedding、搜索条件的embedding，concat两个embedding和age、gender\n",
    "        video_embedding = tf.compat.v1.get_variable('video_embedding', \n",
    "                                                    shape=[self.video_total_num], \n",
    "                                                    dtype=tf.float32,\n",
    "                                                    initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "        \n",
    "        video_vecs = tf.nn.embedding_lookup(params=video_embedding, \n",
    "                                            ids=self.video_ids_ph)\n",
    "        \n",
    "        search_embedding = tf.compat.v1.get_variable(name='search_embedding', \n",
    "                                                     shape=[self.search_total_num], \n",
    "                                                     dtype=tf.float32,\n",
    "                                                     initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "        \n",
    "        search_vec = tf.nn.embedding_lookup(params=search_embedding, \n",
    "                                            ids=self.search_id_ph)\n",
    "        \n",
    "        input = tf.concat([tf.reshape(tf.reduce_mean(input_tensor=video_vecs, axis=1), shape=[-1, 1]),\n",
    "                           tf.reshape(search_vec, shape=[-1, 1]), \n",
    "                           tf.reshape(self.age_ph, shape=[-1, 1]),\n",
    "                           tf.reshape(self.gender_ph, shape=[-1, 1])], axis=1)\n",
    "\n",
    "        # 经过多层深度训练，层数根据mAP确定\n",
    "        for i in range(self.depth):\n",
    "            input = tf.compat.v1.layers.dense(inputs=input,\n",
    "                                              units= self.units_list[i],\n",
    "                                              kernel_regularizer= tf.keras.regularizers.l2(0.001),\n",
    "                                              activation= tf.nn.relu,\n",
    "                                              name='fc{}'.format(i), \n",
    "                                              trainable=self.is_training) \n",
    "            \n",
    "            input = tf.compat.v1.layers.batch_normalization(inputs=input,\n",
    "                                                           training = self.is_training, \n",
    "                                                           name='fc{}_bn'.format(i))\n",
    "                                                       \n",
    "        output = input\n",
    "        \n",
    "        # 初始化类别（就是每个视频的标签，对应论文中的百万级）的embedding对应的：weights和bias\n",
    "        weights = tf.compat.v1.get_variable('soft_weight', \n",
    "                                            shape=[self.class_distinct, 128],\n",
    "                                            initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "        \n",
    "        biases = tf.compat.v1.get_variable('soft_bias',\n",
    "                                           shape=[self.class_distinct],\n",
    "                                           initializer=tf.compat.v1.variance_scaling_initializer())\n",
    "        if not self.is_training:\n",
    "            # 计算预测值\n",
    "            self.logits_out = tf.matmul(output, tf.transpose(a=weights))\n",
    "        else:\n",
    "            # label必须二维的，但是biases却是一维的\n",
    "            self.labels = tf.reshape(self.label_ph, \n",
    "                                     shape=[-1, 1])\n",
    "            # 计算损失, num_true=1代表负采样有一个正例，one-hot值为1。\n",
    "#             self.logits_out, self.labels_out = nn_impl._compute_sampled_logits(weights=weights, biases=biases,\n",
    "#             self.logits_out, self.labels_out = tf.nn._compute_sampled_logits(weights=weights, \n",
    "            self.logits_out, self.labels_out = tf.compat.v1.nn.sampled_softmax_loss(weights=weights,\n",
    "                                                                                    biases=biases, \n",
    "                                                                                    labels=self.labels,\n",
    "                                                                                    inputs=input, \n",
    "                                                                                    num_sampled=100,\n",
    "                                                                                    num_classes=self.class_distinct,\n",
    "                                                                                    num_true=1,\n",
    "                                                                                    sampled_values=None,\n",
    "                                                                                    remove_accidental_hits=True,\n",
    "                                                                                    partition_strategy=\"div\",\n",
    "                                                                                    name=\"sampled_softmax_loss\",\n",
    "                                                                                    seed=None)\n",
    "#             labels = array_ops.stop_gradient(self.labels_out, name=\"labels_stop_gradient\")\n",
    "            labels = tf.stop_gradient(self.labels_out, \n",
    "                                      name=\"labels_stop_gradient\")\n",
    "#             sampled_losses = nn_ops.softmax_cross_entropy_with_logits_v2(labels=labels, logits=self.logits_out)\n",
    "            sampled_losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, \n",
    "                                                                        logits=self.logits_out)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(input_tensor=sampled_losses)\n",
    "            # 获得梯度下降优化器\n",
    "            gradient_descent_optimizer = tf.compat.v1.train.GradientDescentOptimizer(self.learning_rate)\n",
    "            train_var = tf.compat.v1.trainable_variables()\n",
    "            clip_gradients, _ = tf.clip_by_global_norm(tf.gradients(ys=self.loss, xs=train_var), 5)\n",
    "            \n",
    "            self.gradient_descent = gradient_descent_optimizer.apply_gradients(zip(clip_gradients, train_var),\n",
    "                                                                               global_step=self.global_step)\n",
    "    def train(self, session, video_ids, search_id, age, gender, label):\n",
    "        loss, _, step, logits, labels = session.run([self.loss, self.gradient_descent, self.global_step, self.labels_out, self.logits_out],\n",
    "            feed_dict={self.video_ids_ph: video_ids,\n",
    "                       self.search_id_ph: search_id,\n",
    "                       self.age_ph: age,\n",
    "                       self.gender_ph: gender,\n",
    "                       self.label_ph: label})\n",
    "        \n",
    "        return loss, step, logits, labels\n",
    "\n",
    "    def predict(self, session, video_ids, search_id, age, gender):\n",
    "        result = session.run([self.logits_out],\n",
    "                             feed_dict={self.video_ids_ph: video_ids,\n",
    "                                        self.search_id_ph: search_id,\n",
    "                                        self.age_ph: age,\n",
    "                                        self.gender_ph: gender})\n",
    "        return result\n",
    "\n",
    "    def cal_acc(self, session, label, logit):\n",
    "        labels = tf.one_hot(label, self.class_distinct, axis=1)\n",
    "        correct_pred = tf.equal(tf.argmax(input=logit, axis=1), \n",
    "                                tf.argmax(input=labels, axis=1))\n",
    "        \n",
    "        accuracy, labels, logits = session.run([tf.reduce_mean(input_tensor=tf.cast(correct_pred, tf.float32)), \n",
    "                                                labels, logit])\n",
    "        return accuracy, labels, logits\n",
    "\n",
    "    def save(self, session, path):\n",
    "        tf.compat.v1.train.Saver().save(session, path)\n",
    "\n",
    "    def restore(self, session, path):\n",
    "        tf.compat.v1.train.Saver().restore(session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-df2858125ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrecall_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecallModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-8fdea33ea2c6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-8fdea33ea2c6>\u001b[0m in \u001b[0;36minit_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m                                                                                     \u001b[0mpartition_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                                                                                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sampled_softmax_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                                                                                     seed=None)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;31m#             labels = array_ops.stop_gradient(self.labels_out, name=\"labels_stop_gradient\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             labels = tf.stop_gradient(self.labels_out, \n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iterating over `tf.Tensor`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    521\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "training = 'True' \n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "with tf.compat.v1.Session() as session:\n",
    "    recall_model = RecallModel(args)\n",
    "    session.run(tf.compat.v1.global_variables_initializer())\n",
    "    session.run(tf.compat.v1.local_variables_initializer())\n",
    "    \n",
    "    for i in range(args.epoch):\n",
    "        j = 0\n",
    "        while True:\n",
    "            has_more, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = get_batch(page_size=args.batch_num)\n",
    "\n",
    "            step = recall_model.train(session, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch)\n",
    "\n",
    "            print(step)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RecallModel' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-6799f10fc985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#                 video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = list2array(video_ids_batch, dtype='int32'), list2array(search_ids_batch, 'int32'), list2array(age_batch), list2array(gender_batch), list2array(label_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-f63f3770f041>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, session, video_ids, search_id, age, gender, label)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         loss, _, step, logits, labels = session.run(\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             feed_dict={self.video_ids_ph: video_ids,\n\u001b[1;32m    120\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_id_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msearch_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RecallModel' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "training = 'True'\n",
    "# args = Args(is_training=training)\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "with tf.compat.v1.Session() as session:\n",
    "    recall_model = RecallModel(args)\n",
    "    session.run(tf.compat.v1.global_variables_initializer())\n",
    "    session.run(tf.compat.v1.local_variables_initializer())\n",
    "    \n",
    "    if args.is_training:\n",
    "        for i in range(args.epoch):\n",
    "            j = 0\n",
    "            while True:\n",
    "                has_more, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = get_batch(page_size=args.batch_num)\n",
    "                \n",
    "#                 if not has_more:\n",
    "#                     break\n",
    "#                 video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = list2array(video_ids_batch, dtype='int32'), list2array(search_ids_batch, 'int32'), list2array(age_batch), list2array(gender_batch), list2array(label_batch)\n",
    "                \n",
    "                loss, step, logits, labels = recall_model.train(session, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch)\n",
    "                 \n",
    "                print(loss, step)\n",
    "                if j % 1 == 0:\n",
    "                    recall_model.save(session, args.checkpoint_dir + 'utube')\n",
    "                j += 1\n",
    "                \n",
    "    else:\n",
    "        recall_model.restore(session, args.checkpoint_dir)\n",
    "        has_more, video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = get_batch(2, page_size=args.batch_num)\n",
    "        \n",
    "#         if has_more:\n",
    "#             video_ids_batch, search_ids_batch, age_batch, gender_batch, label_batch = list2array(video_ids_batch, 'int32'), \n",
    "#             list2array(search_ids_batch, 'int32'), \n",
    "#             list2array(age_batch), \n",
    "#             list2array(gender_batch), \n",
    "#             list2array(label_batch)\n",
    "            \n",
    "        logits = recall_model.predict(session, \n",
    "                                      video_ids_batch, \n",
    "                                      search_ids_batch, \n",
    "                                      age_batch, \n",
    "                                      gender_batch)[0]\n",
    "\n",
    "        logits = tf.convert_to_tensor(value=logits, \n",
    "                                      dtype=tf.float32, \n",
    "                                      name='predict_logits')\n",
    "\n",
    "        accuracy, labels, logits = recall_model.cal_acc(session, label=label_batch, logit=logits)\n",
    "\n",
    "        print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
