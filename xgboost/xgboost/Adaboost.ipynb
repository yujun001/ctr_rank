{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpData():                            #创建单层决策树数据集\n",
    "    datMat = np.matrix([[ 1. ,  2.1],          #数据矩阵\n",
    "                        [ 1.5,  1.6],\n",
    "                        [ 1.3,  1. ],\n",
    "                        [ 1. ,  1. ],\n",
    "                        [ 2. ,  1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]   #数据标签\n",
    "    return datMat,classLabels\n",
    "\n",
    "def showDataSet(dataMat, labelMat):      #数据可视化\n",
    "    data_plus = []                       #正样本\n",
    "    data_minus = []                      #负样本\n",
    "    for i in range(len(dataMat)):\n",
    "        if labelMat[i] > 0:\n",
    "            data_plus.append(dataMat[i])\n",
    "        else:\n",
    "            data_minus.append(dataMat[i])\n",
    "    data_plus_np = np.array(data_plus)      \n",
    "    data_minus_np = np.array(data_minus) \n",
    "    plt.scatter(np.transpose(data_plus_np)[0], np.transpose(data_plus_np)[1])   #正样本散点图\n",
    "    plt.scatter(np.transpose(data_minus_np)[0], np.transpose(data_minus_np)[1])  #负样本散点图\n",
    "    plt.show()\n",
    "\n",
    "if __name__ =='_main_':\n",
    "    dataArr,classLables=loadSimpData()\n",
    "    showDataSet(dataArr,classLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]\n",
      " [ 0.69314718]]\n",
      "[[-1.66610226]\n",
      " [ 1.66610226]]\n",
      "[[-2.56198199]\n",
      " [ 2.56198199]]\n",
      "[[-1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "    \"\"\"\n",
    "    单层决策树分类函数\n",
    "    Parameters:\n",
    "        dataMatrix - 数据矩阵\n",
    "        dimen - 第dimen列，也就是第几个特征\n",
    "        threshVal - 阈值\n",
    "        threshIneq - 标志\n",
    "    Returns:\n",
    "        retArray - 分类结果\n",
    "    \"\"\"\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1))      #初始化retArray为1\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0  #如果小于阈值,则赋值为-1\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0   #如果大于阈值,则赋值为-1\n",
    "    return retArray\n",
    "    \n",
    "\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    \"\"\"\n",
    "    找到数据集上最佳的单层决策树\n",
    "    Parameters:\n",
    "        dataArr - 数据矩阵\n",
    "        classLabels - 数据标签\n",
    "        D - 样本权重\n",
    "    Returns:\n",
    "        bestStump - 最佳单层决策树信息\n",
    "        minError - 最小误差\n",
    "        bestClasEst - 最佳的分类结果\n",
    "    \"\"\"\n",
    "    dataMatrix = np.mat(dataArr); labelMat = np.mat(classLabels).T\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = np.mat(np.zeros((m,1)))\n",
    "    minError = float('inf')                   #最小误差初始化为正无穷大\n",
    "    for i in range(n):                        #遍历所有特征\n",
    "        rangeMin = dataMatrix[:,i].min(); \n",
    "        rangeMax = dataMatrix[:,i].max()      #找到特征中最小的值和最大值\n",
    "        stepSize = (rangeMax - rangeMin)/numSteps  #计算步长\n",
    "        for j in range(-1, int(numSteps) + 1): \n",
    "            for inequal in ['lt', 'gt']:      #大于和小于的情况，均遍历。lt:less than，gt:greater than\n",
    "                threshVal = (rangeMin + float(j) * stepSize) #计算阈值\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)   #计算分类结果\n",
    "                errArr = np.mat(np.ones((m,1)))        #初始化误差矩阵\n",
    "                errArr[predictedVals == labelMat] = 0  #分类正确的,赋值为0\n",
    "                weightedError = D.T * errArr           #计算误差\n",
    "                # print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                if weightedError < minError:           #找到误差最小的分类方式\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClasEst\n",
    "\n",
    "def adaBoostTrainDS(dataArr, classLabels, numIt = 40):\n",
    "    \"\"\"\n",
    "    使用AdaBoost算法提升弱分类器性能\n",
    "    Parameters:\n",
    "        dataArr - 数据矩阵\n",
    "        classLabels - 数据标签\n",
    "        numIt - 最大迭代次数\n",
    "    Returns:\n",
    "        weakClassArr - 训练好的分类器\n",
    "        aggClassEst - 类别估计累计值\n",
    "    \"\"\"\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m, 1)) / m)       #初始化权重\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D) #构建单层决策树\n",
    "        # print(\"D:\",D.T)\n",
    "        alpha = float(0.5 * np.log((1.0 - error) / max(error, 1e-16))) #计算弱学习算法权重alpha,使error不等于0,因为分母不能为0\n",
    "        bestStump['alpha'] = alpha                      #存储弱学习算法权重 \n",
    "        weakClassArr.append(bestStump)                  #存储单层决策树\n",
    "        # print(\"classEst: \", classEst.T)\n",
    "        expon = np.multiply(-1 * alpha * np.mat(classLabels).T, classEst)  #计算e的指数项\n",
    "        D = np.multiply(D, np.exp(expon))                            \n",
    "        D = D / D.sum()                                 #根据样本权重公式，更新样本权重\n",
    "        #计算AdaBoost误差，当误差为0的时候，退出循环\n",
    "        aggClassEst += alpha * classEst                 #计算类别估计累计值\n",
    "        # print(\"aggClassEst: \", aggClassEst.T)\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m,1)))  #计算误差\n",
    "        errorRate = aggErrors.sum() / m\n",
    "        # print(\"total error: \", errorRate)\n",
    "        if errorRate == 0.0: break #误差为0，退出循环\n",
    "    return weakClassArr, aggClassEst\n",
    "\n",
    "def adaClassify(datToClass,classifierArr):\n",
    "    \"\"\"\n",
    "    AdaBoost分类函数\n",
    "    Parameters:\n",
    "        datToClass - 待分类样例\n",
    "        classifierArr - 训练好的分类器\n",
    "    Returns:\n",
    "        分类结果\n",
    "    \"\"\"\n",
    "    dataMatrix = np.mat(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(len(classifierArr)):         #遍历所有分类器，进行分类\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'], classifierArr[i]['thresh'], classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha'] * classEst\n",
    "        print(aggClassEst)\n",
    "    return np.sign(aggClassEst)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataArr,classLabels = loadSimpData()\n",
    "    weakClassArr, aggClassEst = adaBoostTrainDS(dataArr, classLabels)\n",
    "    print(adaClassify([[0,0],[5,5]], weakClassArr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor, \\\n",
    "    AdaBoostRegressor, RandomForestRegressor\n",
    "\n",
    "X = pd.read_csv('../../results/munged_training.csv')\n",
    "y = pd.read_csv('../../results/munged_labels.csv')\n",
    "\n",
    "# Make a validation set\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X,y,random_state=1848)\n",
    "\n",
    "# Sci-Kit Learn's Out of the Box Gradient Tree Implementation\n",
    "sklearn_boost = GradientBoostingRegressor(random_state=1849)\n",
    "sklearn_boost.fit(X_train, y_train.values.ravel())\n",
    "print('Training Error: {:.3f}'.format(1 - sklearn_boost.score(X_train,\n",
    "                                                              y_train)))\n",
    "print('Validation Error: {:.3f}'.format(1 - sklearn_boost.score(X_validation,\n",
    "                                                                y_validation)))\n",
    "%timeit sklearn_boost.fit(X_train, y_train.values.ravel())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
